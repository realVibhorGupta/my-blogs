---
title: "Understanding the Internal Architecture of PostgreSQL"
seoTitle: "PostgreSQL Internal Architecture Explained"
seoDescription: "Explore PostgreSQL's architecture: processes, shared memory, and Write-Ahead Logging for efficient database performance and data integrity"
datePublished: Sun Sep 22 2024 17:24:54 GMT+0000 (Coordinated Universal Time)
cuid: cm1dumki4000008jq5qt94i4b
slug: understanding-the-internal-architecture-of-postgresql
cover: https://cdn.hashnode.com/res/hashnode/image/upload/v1727024869229/043fba60-3541-4a69-8c9f-01697256b01b.png
ogImage: https://cdn.hashnode.com/res/hashnode/image/upload/v1727025867081/8e71789c-1bd9-4c1a-b4ad-c894ff238e85.png
tags: postgresql, databases, architecture, system-architecture

---

PostgreSQL's architecture involves various processes for maintenance and input/output operations. The main process, known as the "postmaster process," serves as the primary listener on port 5432 for client connections. It is crucial to specify the correct address family (IPv4 or IPv6) when connecting to the database. PostgreSQL refers to many of its processes as "backends," which can be confusing due to the broad use of the term. Key components include shared memory, background workers, and auxiliary processes like autovacuum workers and WAL senders.

PostgreSQL is a relational database system that employs multiversion concurrency control (MVCC), creating new tuples for updates rather than modifying existing data. This design choice distinguishes PostgreSQL from other databases and has its own advantages and disadvantages. PostgreSQL is process-based rather than thread-based, a decision driven by historical stability concerns with threads. Although threads are now generally more efficient, PostgreSQL's choice to use processes was driven by the need for stability in earlier computing environments.

The Translation Lookaside Buffer (TLB) in CPUs translates virtual addresses to physical addresses in RAM. TLB efficiency differs between processes and threads; threads share the page table of their parent process, leading to higher cache hit rates compared to processes that have separate tables. When monitoring system processes, such as in Linux or Windows, many processes are visible, primarily due to the postmaster process that manages client connections to the database. Clients connecting to the database are often backend applications rather than end users, which limits the number of connections compared to web servers. Each client connection results in a new backend process, which can lead to scalability issues if there are many connections, as each process consumes resources. The database has a maximum connection limit, typically set low (e.g., 100), to prevent resource exhaustion. When a new connection is made, the postmaster forks a new process, which requires its own virtual memory space. However, operating systems optimize this with a technique called "copy on write" (COW), where the new process initially shares memory with the postmaster. Only when changes are made to the memory do separate copies get created, allowing for efficient memory usage. While the process model may seem inefficient, improvements in database management have minimized the overhead associated with these backend processes.

Shared memory, also known as shared buffers or buffer pools, is crucial for storing data that multiple processes need to access. Processes must use synchronization mechanisms like mutexes and semaphores to avoid race conditions when accessing shared memory. Background workers, introduced in 1996, handle query execution more efficiently. When a backend process receives a query, it can either execute it directly or delegate the work to background workers if parallel processing is enabled. This approach allows for predictable resource management, as the number of background workers can be limited. Auxiliary processes, specifically the background writer, are responsible for flushing dirty pages (modified data) from shared memory to disk for durability. The background writer communicates with the operating system to initiate this write operation, which is first stored in the OS's file system cache before being written to disk. This caching mechanism improves performance by reducing the frequency of direct disk writes.

Writing operations on SSDs and databases can slow down performance and reduce the SSD's lifespan due to the limited number of write cycles each cell can endure. The background writer manages memory by flushing "dirty pages" to free up space for new data, essential for maintaining efficient database operations. The checkpoint process involves flushing all changes to disk to create a consistent state, crucial for data integrity, especially during a crash, as it allows for recovery by replaying changes made after the checkpoint. The logging process records errors and other information, and the autovacuum process cleans up old data to prevent bloat in the database. The autovacuum launcher starts these cleanup processes, ensuring that the database remains efficient. Write-Ahead Logging (WAL) is vital for data recovery and replication, as it keeps a record of changes made to the database, which is essential for restoring data after a crash. These processes are critical for maintaining database performance and integrity.

The Write-Ahead Logging (WAL) mechanism is crucial for maintaining data integrity during transactions. The WAL archives changes made to the database, allowing the system to replay these changes to restore the database to a specific state if needed. The WAL writer is responsible for writing these records and ensuring they are flushed to disk before a transaction is considered committed. If the WAL is not flushed and a crash occurs, data could be lost, making the WAL writer's role critical. When a transaction is committed, the WAL writer flushes the changes, while the checkpoint process handles both the WAL and the database pages. If a crash occurs, the startup process uses the last checkpoint to apply any changes recorded in the WAL to the database pages, effectively "redoing" the changes to bring the database back to its last consistent state. This process highlights the WAL's function as a redo log, while PostgreSQL's design eliminates the need for undo logs, relying instead on multi-version concurrency control (MVCC) to manage data consistency.